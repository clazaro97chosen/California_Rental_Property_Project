{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello this is the jupyter file that demonstrates how to attain housing market research from towncharts.com for a given list of cities from a state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a snapshot of the web page for a given city. We will be scraping the pieces of information included in this web page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"towncharts.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data dictionary 35 pieces of information: provided by Towncharts.com\n",
    "\n",
    "* city_name: Name of city\n",
    "* housing_units:Total number of housing units in the area\n",
    "* housing_density : The number of housing units per square mile in the area\n",
    "* change_hunits: Change in housing units from 2010 to 2017\n",
    "* percent_of_rent_to_total: The percent of all occupied housing units that are rental housing units (%)\n",
    "* owned_homes: The percent of all occupied housing units that are owned housing units (%)\n",
    "* med_homeval: Median home value i.e how much property is worth( house and lot, mobile homes and lot, or condominium unit) if it was for sale \\$\n",
    "\n",
    "* med_rental_rate: the median monthly rental amount for a rental unit in this area \\$\n",
    "\n",
    "* med_owner_cost: The monthly cost of housing for property owners including mortgage payment, taxes, insurance,and utilities.\\$\n",
    "\n",
    "* med_own_cost_aspercentof_income: The monthly owner cost as a percent of the household income. This measure is an excellent way to understand how affordable housing is for owners in an area (%)\n",
    "* med_hval_aspercentof_medearn: How much the property is worth(house and lot, mobile home and lot, or condominium unit) if it was for sale as a percent of the median earnings for a worker in the area (%)\n",
    "* med_hcost_ownmortg: Median housing cost for homeowners with a mortgage(including the cost of the mortgage or other debt) \\$\n",
    "* med_hcost_own_wo_mortg: Median housing cost for homeowners who do not have a mortgage. This isolates the cost of ownership seperate from the financing cost of debt \\$\n",
    "* hcost_aspercentof_hincome_ownmortg: Homeowners with a mortgage showing total cost (including mortgage debt) as a percent of household income (%)\n",
    "* hcost_as_perc_of_hincome_womortg: Homeowners without a mortgage showing total cost as a percent of household income.\n",
    "\n",
    "* med_real_estate_taxes: The median real estate taxes paid by owners of homes in the area\\$\n",
    "\n",
    "* family_members_per_hunit: The average size of related families members who live together in a housing unit. \n",
    "* median_num_ofrooms: The average number of rooms of total rooms for housing units in the area\n",
    "* median_year_house_built: The average year the housing units were built in the area. This indicates the average age of housing units in the area.\n",
    "* household_size_of_howners: For people who own their homes how many people on average are living in them whether they are part of family or related or not. \n",
    "* household_size_for_renters: The average size of a household for people who are renting.\n",
    "* med_year_moved_in_for_owners: The median year that a home owner moved into their home\n",
    "* med_year_renter_moved_in: The median year that a renter moved into their home \n",
    "* The following varialbes are monthly rental rates by size of  Rental in Bedrooms as a percentage\n",
    "studio_1000_1499,\n",
    "studio_1500_more,\n",
    "studio_750_999,\n",
    "onebed_1000_1499,\n",
    "onebed_1500_more,\n",
    "onebed_750_999,\n",
    "twobed_1000_1499,\n",
    "twobed_1500_more,\n",
    "twobed_750_999,\n",
    "threebed_1000_1499,\n",
    "threebed_1500_more,\n",
    "threebed_750_999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the prerequisite libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from googlesearch import search\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gather our list of cities in California from the Name column in a dataset from Kaggle.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_data = pd.read_csv('C:\\\\Users\\\\Crist\\\\Towncharts\\\\California_Housing_Project\\\\datasets\\\\cal_cities_lat_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_data.Name.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list = cities_data.Name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_city_list(listofcities):\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "            listofcities (list): a case sensitive list of cities with appropriate capitalization\n",
    "            and spaces for cities with multiple words\n",
    "\n",
    "    Returns:\n",
    "            newlist: list of cities with \" \" replaced with - for google search to work\n",
    "    \"\"\"\n",
    "    list_of_cities = []\n",
    "    for city in listofcities:\n",
    "        new = city.replace(' ','-')\n",
    "        list_of_cities.append(new)\n",
    "    return list_of_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_cities = preprocess_city_list(city_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Livingston', 'Lodi', 'Loma-Linda', 'Lomita', 'Lompoc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_cities[220:225]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is responsible for finding the url link to scrape the appropriate housing information from towncharts.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to note we are not targeting ccd or cdp designated locations our population of interest does not include them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchgoogle(nameofstate,stateabbr,list_of_cities):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "                nameofstate: casesensitive use typical spelling \n",
    "                stateabbr: state abbreviation case sensitve must be formated in caps\n",
    "                listofcities (list): a list of cities for a state with \"\"-\"\" between multiple words \n",
    "                acceptccd:\n",
    "\n",
    "    Returns:\n",
    "                a dictionary with keys \n",
    "                theclean: url links for towncharts.com housing data for each city in list of cities inputed to the function\n",
    "                themissing: unfound google search url links  for towncharts.com housing data for cities in list of cities. \n",
    "    \"\"\"\n",
    "    #results lists\n",
    "    clean_links = []\n",
    "    missing_cities = []\n",
    "    \n",
    "    if \" \" in nameofstate:\n",
    "        nameofstate = nameofstate.replace(' ', '-')\n",
    "    \n",
    "    #begin searching\n",
    "    for city in list_of_cities:\n",
    "        backup_url = \"https://www.towncharts.com/{}/Housing/{}-city-{}-Housing-data.html\".format(nameofstate,city,stateabbr)\n",
    "        query  = \"'https://www.towncharts.com/{}/Housing/{}-city-{}-Housing-data.html'\".format(nameofstate,city,stateabbr)\n",
    "        query = urllib.parse.quote_plus(query) # Format into URL encoding\n",
    "        number_result = 3\n",
    "        \n",
    "        ua = UserAgent()\n",
    "        \n",
    "        google_url = \"https://www.google.com/search?q=\" + query + \"&num=\" + str(number_result)\n",
    "        #setting up a delay\n",
    "        t0 = time.time()\n",
    "        response = requests.get(google_url, {\"User-Agent\": ua.random})\n",
    "        response_delay = time.time() - t0\n",
    "        time.sleep(10*response_delay)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        result_div = soup.find_all('div', attrs = {'class': 'ZINbbc'})\n",
    "        links = []\n",
    "        for r in result_div:\n",
    "            \n",
    "            try:\n",
    "                link = r.find('a', href = True)\n",
    "                if link != '':\n",
    "                    links.append(link['href'])\n",
    "            except:\n",
    "                continue\n",
    "        flag = True\n",
    "        for i, l in enumerate(links):\n",
    "            clean = re.search('\\/url\\?q\\=(.*)\\&sa',l)\n",
    "            if clean is None:\n",
    "                continue\n",
    "            #clean.group(1) i.e alink such as https://www.towncharts.com/South-Carolina/Housing/Charleston-city-SC-Housing-data.html    \n",
    "            elif city in clean.group(1):\n",
    "                clean_links.append(clean.group(1))\n",
    "                flag = False\n",
    "        \n",
    "        if flag:\n",
    "            missing_cities.append(city)\n",
    "            #using our a default formatted url in place as our backup url\n",
    "            clean_links.append(backup_url)\n",
    "    return {'thefound':clean_links.copy(),'themissing':missing_cities.copy()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "googleresults = searchgoogle('California','CA',list_of_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommended to use the pickle module to save your results from the function above. \n",
    "Uncomment the lines below to save the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outfile = open('my_clean_links','wb')\n",
    "# pickle.dump(googleresults,outfile)\n",
    "# outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the the clean links and missing links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile = open('my_clean_links','rb')\n",
    "# googleresults = pickle.load(infile)\n",
    "# infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_links = googleresults['thefound'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The found links will not always be necessarily the intended results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create a function to clean our Google links since every cities housing data URL for towncharts.com has a consistent format <br> \"http://www.towncharts.com/(**nameof state with \"-\" separating words**)/Housing/(**name of city with \"-\" separating words**)-city-(**state abbreviation**)-Housing-data.html\" since we know this we can create a function to make sure they are in this format for example the City: San Luis Obispo, State:California correct housing data URL is http://www.towncharts.com/California/Housing/San-Luis-Obispo-city-CA-Housing-data.html. We could hardcode this in our function `searchgoogle`  but what if we wanted to actually see the cities Google was unable to find the housing data for and what it returned instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_my_links(found_links,statename,stateabbr):\n",
    "    \"\"\"\n",
    "    args:\n",
    "            statename: the name of the state with \"-\" between words\n",
    "            found_links:a list of google url links for towncharts.com for cities in a certain state\n",
    "            stateabbr: capitalized state abbreviation\n",
    "    returns:\n",
    "            a dictionary: with \n",
    "            clean_urls:a list of urls for towncharts.com **housing data** \n",
    "            invalid_results: a list of URLs that were not towncharts.com **housing data** or cdp/cdd\n",
    "    \"\"\"\n",
    "    #Making the list of clean_links into a pandas series will help vectorize cleaning our results\n",
    "    found_links = pd.Series(found_links)\n",
    "    #drop dupllicates\n",
    "    city_urls = found_links.drop_duplicates().reset_index(drop=True)\n",
    "    #list to save which indices\n",
    "    indexes_to_replace = []\n",
    "    #finds the urls in which google returned something other than the housing data url\n",
    "    for i,v in enumerate(city_urls):\n",
    "        v = pd.Series(v)\n",
    "        check = v.str.extract('\\/{}\\/(.*?)\\/'.format(statename),expand = False)\n",
    "        if 'Housing' not in check[0]:\n",
    "            indexes_to_replace.append(i)\n",
    "    \n",
    "    #finds the urls in which google returned the CDP or CDD\n",
    "  \n",
    "    for i,v in enumerate(city_urls):\n",
    "        v=pd.Series(v)\n",
    "        check = re.findall('City',v[0])\n",
    "        check2 = re.findall('city',v[0])\n",
    "        if ( (check == []) & (check2 == []) ):\n",
    "            indexes_to_replace.append(i)\n",
    "    print('This the number of city URLs before invalid cities and duplicates: ',len(city_urls))   \n",
    "    \n",
    "    invalid_results = city_urls.iloc[indexes_to_replace]\n",
    "    #Going to find which cities google was not able to find a \n",
    "    #suitable url. In effect gathering the city names and indexes \n",
    "    #so we may use the backup url in place of the current value (this could be implemented in the gathering of results as well)         \n",
    "    \n",
    "    incomplete_urls = city_urls.drop(labels = indexes_to_replace)\n",
    "    \n",
    "    #list comprehsion yay!!!\n",
    "    cities_to_add =[ city for city in list_of_cities if incomplete_urls[incomplete_urls.str.contains(city)].empty ] \n",
    "\n",
    "    fill_indexes = [ city_urls[city_urls.str.contains(city)].index[0] for city in cities_to_add]\n",
    "            \n",
    "    \n",
    "    city_urls = city_urls.drop(labels = indexes_to_replace)\n",
    "    \n",
    "    #Actually take them out add them where they were and then reset index\n",
    "    cities_to_fix = pd.Series(cities_to_add,index = fill_indexes)\n",
    "    \n",
    "    \n",
    "    for i,v in cities_to_fix.items():\n",
    "        city_urls = city_urls.append( pd.Series([\"https://www.towncharts.com/{}/Housing/{}-city-{}-Housing-data.html\".format(statename,v,stateabbr)],index = [i]) )\n",
    "        city_urls.reset_index(inplace= True,drop=True)\n",
    "    \n",
    "    city_urls = city_urls.drop_duplicates().reset_index(drop=True)\n",
    "    print('After cleaning this is the number of links for the cities : ' , len(city_urls))\n",
    "\n",
    "          \n",
    "          \n",
    "    return {'clean_urls':city_urls,'invalid_results':invalid_results} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This the number of city URLs before invalid cities and duplicates:  467\n",
      "After cleaning this is the number of links for the cities :  458\n"
     ]
    }
   ],
   "source": [
    "clean_my_links_results = clean_my_links(found_links,'California','CA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_urls = clean_my_links_results['clean_urls'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets get scraping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we actually scrape the desired attributes:\n",
    "<br>\n",
    "Out of the displayed pieces of information in a housing web page  for a city \n",
    "information from the figures: 3,9,13,16,19,20,22,23,25,26,27,31,32,33,34,35,38,39 (18) will not be included due to inconsistencies. Some cities might not have the figure information and an NA will be put in place. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have three helper functions that help our `get_housing_data`\n",
    "scraper. Which use [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) and [Regular Expressions](https://docs.python.org/3/howto/regex.html) to make life a lot easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_section(target_section,mysoup):\n",
    "    \"\"\"\n",
    "    Attains the appropriate text section from the **left side bar** for towncharts.com\n",
    "    each housing data webpage for a city has 4 in total the third being an ad\n",
    "    Args:\n",
    "        target_section: div class = 'target_section'\n",
    "        mysoup: a Beautiful Soup soup object\n",
    "    Returns: \n",
    "        text_section\n",
    "    \"\"\"\n",
    "    found = mysoup.find_all('div',attrs = {'class':target_section})\n",
    "    validsection = found[0]\n",
    "    text_section = validsection.find_all(text=True)\n",
    "    return text_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchpattern(pattern,resultset):\n",
    "    '''\n",
    "    Finds regex pattern for a beautiful soup result set\n",
    "    Args:\n",
    "        pattern:regex pattern\n",
    "        resultset: A beautiful soup result set\n",
    "        \n",
    "    Returns:\n",
    "         housing variable of interest type string\n",
    "    '''\n",
    "    result = [i for i in resultset if re.search(pattern,i)]\n",
    "    if result == []:\n",
    "        result  = None\n",
    "    elif result !=[]:\n",
    "        result = (re.findall(pattern,result[0]))[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refinestring(desiredreplacement,yourstring):\n",
    "    \"\"\"\n",
    "    Replace undesired characters in a string with your choosing\n",
    "    Args:\n",
    "        yourstring: a string which you wish to replace certain characters\n",
    "        desiredreplacement: a dictonary definining your replacement values\n",
    "    Returns:\n",
    "        yourstring argument with the desired replacements you request \n",
    "    \"\"\"\n",
    "    if yourstring  == None:\n",
    "        return None\n",
    "    elif yourstring != None:\n",
    "        rep = dict((re.escape(k),v) for k,v in desiredreplacement.items())\n",
    "        pattern =re.compile(\"|\".join(rep.keys()))\n",
    "\n",
    "        return float(pattern.sub(lambda m:rep[re.escape(m.group(0))],yourstring))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the function that will attempt to gather the housing data variables from towncharts.com for each city URL we pass.  It might take some time for me with my 6GB of ram  it took about 20 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_housing_data(clean_urls,statename,stateabbr):\n",
    "    \"\"\"\n",
    "    Attempts to attain 36 pieces of information from a cities towncharts.com webpage\n",
    "    Args:\n",
    "        clean_ulrs: A pandas series or list containing towncharts.com URLs for cities in a state\n",
    "        statename: case sensitive best practice is proper spelling but with \"-\" instead of spaces\n",
    "        stateabbr: all upper case state abbreviation\n",
    "    Returns:\n",
    "        A dictionary with two keys \n",
    "        'results'- a list where each element is a tuple representing a city with 36 values obtained from towncharts.com\n",
    "        'not found' -  a list of towncharts.com city urls that where not able to be found\n",
    "        \n",
    "    \"\"\"\n",
    "    results = []\n",
    "    not_found = []\n",
    "    for aurl in clean_urls:\n",
    "        #to prevent from being blocked \n",
    "        ua = UserAgent()\n",
    "        t0 = time.time()\n",
    "        response = requests.get(aurl,{\"User-Agent\": ua.random})\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            not_found.append(aurl)\n",
    "            continue\n",
    "\n",
    "        response_delay = time.time() - t0\n",
    "        time.sleep(10*response_delay)\n",
    "\n",
    "        soup = BeautifulSoup(response.text,'html.parser')\n",
    "        #The code above parses the HTML (stored in r.text) into a special object \n",
    "        #called soup that the Beautiful Soup library understands. \n",
    "        #In other words, Beautiful Soup is reading the HTML and making sense of its structure\n",
    "\n",
    "        housing_text_section1 = get_text_section('section1',soup)\n",
    "        housing_text_section2 = get_text_section('section2',soup)\n",
    "        housing_text_section3 = get_text_section('section4',soup)\n",
    "\n",
    "        #everything below gathers the variables\n",
    "        if re.search('(.*)\\s{}'.format(statename),housing_text_section1[0]) == None:\n",
    "            city_name = (pd.Series(aurl)).str.extract('Housing\\/(.*?)-CA'.format())\n",
    "        elif re.search('(.*)\\s{}'.format(statename),housing_text_section1[0]) != None:\n",
    "            city_name = re.search('(.*)\\sCalifornia'.format,housing_text_section1[0]).group(1)\n",
    "\n",
    "        #for variables need to remove everything but numbers\n",
    "        #figure1 \n",
    "        housing_units = searchpattern('it\\shas\\s(\\d.*?\\d)\\shousing\\sunits\\s',housing_text_section1)\n",
    "        housing_units = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},housing_units)\n",
    "\n",
    "\n",
    "        #figure2 \n",
    "        housing_density = searchpattern('it\\shas\\s(\\d.*?\\d)\\shousing\\sdensity\\s',housing_text_section1)\n",
    "        housing_density = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},housing_density)\n",
    "\n",
    "        #figure4 \n",
    "        change_hunits = searchpattern('it\\shas\\s(.*?%)\\schange\\sin\\s',housing_text_section1)\n",
    "        change_hunits = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},change_hunits)\n",
    "\n",
    "        #figure5\n",
    "        percent_of_rent_to_total = searchpattern('it\\shas\\s(\\d.*?%)\\sRenter\\sPercent\\s',housing_text_section1)\n",
    "        percent_of_rent_to_total = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},percent_of_rent_to_total)\n",
    "\n",
    "\n",
    "        #figure 6\n",
    "        owned_homes = searchpattern('it\\shas\\s(\\d.*?%)\\sOwner\\sPercent\\s',housing_text_section1)\n",
    "        owned_homes = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},owned_homes)\n",
    "\n",
    "        #figure 7 median home value (unique character  = $-numbers-commas)\n",
    "        med_homeval = searchpattern('it\\shas\\s(.*?\\d)\\smedian\\shome\\svalue\\s',housing_text_section2)\n",
    "        med_homeval = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},med_homeval)\n",
    "\n",
    "        #figure 8 median rental rate\n",
    "        med_rental_rate = searchpattern('it\\shas\\s(.*?\\d)\\srental\\srates\\s',housing_text_section2)\n",
    "        med_rental_rate = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},med_rental_rate)\n",
    "\n",
    "        #figure 10 median owner costs\n",
    "        med_owner_cost = searchpattern(\"it\\shas\\s(.*?\\d)\\smedian\\sownership\\scost\\s\",housing_text_section2)\n",
    "        med_owner_cost = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},med_owner_cost)\n",
    "\n",
    "        #figure 11\n",
    "        med_own_cost_aspercentof_income = searchpattern('median\\sowner\\scost\\sas\\sa\\spercent\\sof\\stotal\\shousehold\\sincome\\sand\\sit\\shas\\s(\\d.*?%)',housing_text_section2)\n",
    "        med_own_cost_aspercentof_income = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},med_own_cost_aspercentof_income)\n",
    "\n",
    "\n",
    "        #figure 12 median home value as a percent of a median workers earnings\n",
    "        med_hval_aspercentof_medearn = searchpattern(\"it\\shas\\s(\\d.*?%)\\smedian\\shome\\svalue\\sas\\s\",housing_text_section2)\n",
    "        med_hval_aspercentof_medearn = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},med_hval_aspercentof_medearn)\n",
    "\n",
    "\n",
    "        #figure14\n",
    "        med_hcost_ownmortg = searchpattern('depicts.*\\$(.*?\\d)\\smedian',housing_text_section2)\n",
    "        med_hcost_ownmortg = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},med_hcost_ownmortg)\n",
    "\n",
    "\n",
    "        #figure 15\n",
    "        med_hcost_own_wo_mortg = searchpattern('are.*\\$(.*?\\d)\\smedian\\shousing\\s',housing_text_section2)\n",
    "        med_hcost_own_wo_mortg = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},med_hcost_own_wo_mortg)\n",
    "\n",
    "        #figure 17\n",
    "        hcost_aspercentof_hincome_ownmortg= refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},searchpattern('with\\smortgages.*\\s(\\d.*?%)\\scost',housing_text_section2))\n",
    "\n",
    "\n",
    "\n",
    "        #figure18\n",
    "        hcost_as_perc_of_hincome_womortg = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},searchpattern('This\\sanalysis.*\\s(\\d.*?%)\\scost',housing_text_section2))\n",
    "\n",
    "\n",
    "        #figure 21 **\n",
    "        med_real_estate_taxes = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},searchpattern('it\\shas\\s(.*?\\d)\\smedian\\sreal\\sestate\\s',housing_text_section2))\n",
    "        \n",
    "\n",
    "        #figure 28 format 3.0\n",
    "        family_members_per_hunit = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},searchpattern('it\\shas\\s(.*?\\d)\\sfamily\\smembers\\sper\\s',housing_text_section3))\n",
    "\n",
    "\n",
    "        #figure 29 4.5\n",
    "        median_num_ofrooms = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},searchpattern('it\\shas\\s(.*?\\d)\\saverage\\snumber\\sof\\s',housing_text_section3))\n",
    "\n",
    "\n",
    "        #figure 30\n",
    "        median_year_house_built = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},searchpattern('it\\shas\\s(.*?\\d)\\syear\\sbuilt\\swhich\\s',housing_text_section3))\n",
    "\n",
    "\n",
    "        #figure 36\n",
    "        household_size_of_howners = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},searchpattern('it\\shas\\s(.*?\\d)\\shomeowner\\shousehold\\ssize\\s',housing_text_section3))\n",
    "\n",
    "\n",
    "        #figure 37\n",
    "        household_size_for_renters = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},searchpattern('it\\shas\\s(.*?\\d)\\srenter\\shousehold\\ssize\\s',housing_text_section3))\n",
    "        #figure 40\n",
    "        med_year_moved_in_for_owners = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},searchpattern('it\\shas\\s(.*?\\d)\\smedian\\syear\\sthat\\sa\\shome',housing_text_section3))\n",
    "        #figure41\n",
    "        med_year_renter_moved_in = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},searchpattern('it\\shas\\s(.*?\\d)\\smedian\\syear\\sthat\\sa\\srenter',housing_text_section3))\n",
    "\n",
    "        ##figure 24 biggie see below scraping the table\n",
    "\n",
    "        javascript = soup.find_all('script',attrs = {'type':'text/javascript'})\n",
    "        need = javascript[4]\n",
    "        needtext = str(need.find_all(text=True))\n",
    "        \n",
    "\n",
    "        if re.search('data24\\s\\=\\sgoogle\\.visualization\\.arrayToDataTable\\((.*?)\\);',needtext) == None:\n",
    "            # i.e. the webpage does not have figure 24\n",
    "            studio_1000_1499 = None\n",
    "            onebed_1000_1499 = None\n",
    "            twobed_1000_1499 = None\n",
    "            threebed_1000_1499 = None\n",
    "            studio_1500_more = None\n",
    "            onebed_1500_more = None\n",
    "            twobed_1500_more = None\n",
    "            threebed_1500_more = None\n",
    "            studio_750_999 = None\n",
    "            onebed_750_999 = None\n",
    "            twobed_750_999 = None\n",
    "            threebed_750_999 = None\n",
    "        elif re.search('data24\\s\\=\\sgoogle\\.visualization\\.arrayToDataTable\\((.*?)\\);',needtext) != None:\n",
    "\n",
    "            fig24 = re.search('data24\\s\\=\\sgoogle\\.visualization\\.arrayToDataTable\\((.*?)\\);',needtext).group(1)\n",
    "            list_strs = re.findall(r'\\[(.*?)\\]',fig24)\n",
    "            \n",
    "            \n",
    "            #gathering the variables in the table\n",
    "            check1 = True\n",
    "            check2 = True\n",
    "            check3 = True\n",
    "            for i,v in enumerate(list_strs):\n",
    "                if '$1,000 to $1,499' in v:\n",
    "                    check1 = False\n",
    "                    val1 = re.findall('v\\:(.*?\\d),',v)\n",
    "                    studio_1000_1499 = float(val1[0])\n",
    "                    onebed_1000_1499 = float(val1[1])\n",
    "                    twobed_1000_1499 = float(val1[2])\n",
    "                    threebed_1000_1499 = float(val1[3])\n",
    "                elif '$1,500 or more' in v:\n",
    "                    check2 = False\n",
    "                    val2 = re.findall('v\\:(.*?\\d),',v)\n",
    "                    studio_1500_more = float(val2[0])\n",
    "                    onebed_1500_more = float(val2[1])\n",
    "                    twobed_1500_more = float(val2[2])\n",
    "                    threebed_1500_more = float(val2[3])\n",
    "                elif '$750 to $999' in v:\n",
    "                    check3 = False\n",
    "                    val3 = re.findall('v\\:(.*?\\d),',v)\n",
    "                    studio_750_999 = float(val3[0])\n",
    "                    onebed_750_999 = float(val3[1])\n",
    "                    twobed_750_999 = float(val3[2])\n",
    "                    threebed_750_999 = float(val3[3])\n",
    "\n",
    "            if check1:\n",
    "                studio_1000_1499 = None\n",
    "                onebed_1000_1499 = None\n",
    "                twobed_1000_1499 = None\n",
    "                threebed_1000_1499 = None\n",
    "\n",
    "            if check2:\n",
    "                studio_1500_more = None\n",
    "                onebed_1500_more = None\n",
    "                twobed_1500_more = None\n",
    "                threebed_1500_more = None\n",
    "\n",
    "            if check3:\n",
    "                studio_750_999 = None\n",
    "                onebed_750_999 = None\n",
    "                twobed_750_999 = None\n",
    "                threebed_750_999 = None\n",
    "\n",
    "        results.append((city_name,housing_units,housing_density,change_hunits,percent_of_rent_to_total,owned_homes,\n",
    "               med_homeval,med_rental_rate,med_owner_cost,med_own_cost_aspercentof_income,med_hval_aspercentof_medearn,\n",
    "              med_hcost_ownmortg,med_hcost_own_wo_mortg,hcost_aspercentof_hincome_ownmortg,hcost_as_perc_of_hincome_womortg,\n",
    "              med_real_estate_taxes,family_members_per_hunit,median_num_ofrooms,median_year_house_built,household_size_of_howners,household_size_for_renters,\n",
    "              med_year_moved_in_for_owners,med_year_renter_moved_in,studio_1000_1499,studio_1500_more,studio_750_999,onebed_1000_1499,onebed_1500_more,onebed_750_999,\n",
    "              twobed_1000_1499,twobed_1500_more,twobed_750_999,threebed_1000_1499,threebed_1500_more,threebed_750_999))\n",
    "    \n",
    "    return results,not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, not_found = get_housing_data(clean_urls,statename,stateabbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would recommend taking a quick look at results and not_found "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results),len(not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.towncharts.com/California/Housing/Carmel-By-the-Sea-city-CA-Housing-data.html',\n",
       " 'https://www.towncharts.com/California/Housing/La-Ca√±ada-Flintridge-city-CA-Housing-data.html',\n",
       " 'https://www.towncharts.com/California/Housing/Paso-Robles-city-CA-Housing-data.html',\n",
       " 'https://www.towncharts.com/California/Housing/St.-Helena-city-CA-Housing-data.html',\n",
       " 'https://www.towncharts.com/California/Housing/Ventura-city-CA-Housing-data.html']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally create your Dataframe using `create_sheet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sheet(results):\n",
    "    housing = pd.DataFrame(results,columns =['city_name','housing_units','housing_density','change_hunits','percent_of_rent_to_total','owned_homes',\n",
    "                'med_homeval','med_rental_rate','med_owner_cost','med_own_cost_aspercentof_income','med_hval_aspercentof_medearn',\n",
    "                'med_hcost_ownmortg','med_hcost_own_wo_mortg','hcost_aspercentof_hincome_ownmortg','hcost_as_perc_of_hincome_womortg',\n",
    "                'med_real_estate_taxes','family_members_per_hunit','median_num_ofrooms','median_year_house_built','household_size_of_howners','household_size_for_renters',\n",
    "                'med_year_moved_in_for_owners','med_year_renter_moved_in','studio_1000_1499','studio_1500_more','studio_750_999','onebed_1000_1499','onebed_1500_more',\n",
    "                 'onebed_750_999','twobed_1000_1499','twobed_1500_more','twobed_750_999','threebed_1000_1499','threebed_1500_more','threebed_750_999'] )\n",
    "    return housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = create_sheet(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing.to_csv('path_to_save_to')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some reflecting I really wanted the population of each \n",
    "city so i chose to gather said variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_links = {}\n",
    "for city in cities_data.Name:\n",
    "    population_links[city] = 'http://www.towncharts.com/California/Demographics/{}-city-CA-Demographics-data.html'.format(city)\n",
    "population_dict = {}\n",
    "for key,value in population_links.items():\n",
    "    ua = UserAgent()\n",
    "    t0 = time.time()\n",
    "    response = requests.get(value,{\"User-Agent\": ua.random})\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        continue\n",
    "    response_delay = time.time() - t0\n",
    "    time.sleep(10*response_delay)\n",
    "    soup = BeautifulSoup(response.text,'html.parser')\n",
    "    population_text_section = get_text_section('section1',soup)\n",
    "    population = searchpattern('it\\shas\\s(\\d.*?\\d)\\spopulation\\s',population_text_section)\n",
    "    population = refinestring({\"$\":\"\",\",\":\"\",\"%\":\"\"},population)\n",
    "    population_dict[key] = population\n",
    "population_dat = pd.DataFrame(list(population_dict.items()),columns =['city','population'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_dat['city'] = population_dat['city'].str.replace('-',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#population_dat.to_csv('C:\\\\Users\\\\Crist\\\\Towncharts\\\\California_Housing_Project\\\\datasets\\\\population_dat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
